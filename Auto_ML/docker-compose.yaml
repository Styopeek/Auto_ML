version: '3.8'

x-airflow-common: &airflow-common
  image: apache/airflow:2.8.1-python3.8
  environment:
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    MLFLOW_TRACKING_URI: http://mlflow:5000
    MLFLOW_MODEL_NAME: titanic_classifier
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./data:/opt/airflow/data
    - ./training:/opt/airflow/training
    - ./drift_utils:/opt/airflow/drift_utils
    - ./mlflow_utils:/opt/airflow/mlflow_utils
    - ./requirements.txt:/requirements.txt
  depends_on:
    - postgres
    - mlflow
  entrypoint: >
    bash -c "
    pip install --no-cache-dir -r /requirements.txt &&
    exec \"$@\"
    "

services:
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.9.2
    ports:
      - "5000:5000"
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri sqlite:///mlflow.db
      --default-artifact-root /mlflow/artifacts
    volumes:
      - ./mlflow:/mlflow

  airflow-init:
    <<: *airflow-common
    command: >
      bash -c "
      airflow db init &&
      airflow users create
        --username admin
        --password admin
        --firstname admin
        --lastname admin
        --role Admin
        --email admin@example.com
      "

  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - "8080:8080"

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
